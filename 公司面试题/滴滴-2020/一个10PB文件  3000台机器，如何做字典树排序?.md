**字典序：从小到大类似abcd这样的顺序**
> 问题：比如10pb文件全在机器a,然后给你3000台机器,你怎么调度起来这些机器，对他做排序?数据都是“jdflkajogenkngnlkjdlfjwlengp”这样的数据！
## 先将大问题分解为小问题：
1. 怎么切割文件 
2. 分发到1000台机器的策略 
3. 最后怎么合并成字典序文件

### 一、怎么切割文件 
1. 通过split
了解一下split的机制！不行，spilt会一次加载出来！  

2. 通过seek
seek可以直接定位到文件的指定位置，seek会从偏移量开始读。

3. iomap将文件映射进内存
用iomap 将文件数据映射进入内存，不要映射全部 至映射部分 然后偏移一下，然后机器ip 进行一致性hash 给到其他机器。映射进入内存的采用 从尾部寻找\r\n 进行数据行切割

### 二、分发到1000台机器的策略 
1. 通过网络传输

2.通过磁盘挂载

讨论：
假设是放到固态，每秒吞吐1000MB，10pb大概是10*1000*1000，115天加载完成。
要是通过拆硬盘的方式，三千台机器要拆多久？

### 三、最后怎么合并成字典序文件

1. 对大文件做随机采样。 来确定下hash 分布后的情况。大致算下命中率
2.seek 分割3000份  然后rsync 到 3000台机器。
3. 根据第一步的 概率 做hash. 分割 hash保证比较均匀的数据排列
4.就做典型的字典排序咯~ 然后 按照机器1-3000台。 文建索引链接就可以了。
5. 如果需要对这个文件做查询、 我们可以自建维护个 索引。 这就更有意思了。 面试官会对你刮目相看的。

参考链接：[应用访问地域排名分析](https://segmentfault.com/a/1190000020916113)

**旁路话题：单线程还是多线程读文件**
结论：单线程快！
分析：IO已经跑满了，多线程的切换反而浪费CPU时间。
**注意：**区分顺序读和随机读在采用单线程或者多线程。
